{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ceeab81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\anaconda3\\envs\\pyproject\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\yashs\\anaconda3\\envs\\pyproject\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "C:\\Users\\yashs\\anaconda3\\envs\\pyproject\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression # Logistic Regression\n",
    "from sklearn.neighbors import KNeighborsClassifier # K-Nearest Neighbbors\n",
    "from sklearn.tree import DecisionTreeClassifier # Decision Tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40682050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9376d062",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_csv(\"Dataset/criminal_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9a26d2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PERID</th>\n",
       "      <th>IFATHER</th>\n",
       "      <th>NRCH17_2</th>\n",
       "      <th>IRHHSIZ2</th>\n",
       "      <th>IIHHSIZ2</th>\n",
       "      <th>IRKI17_2</th>\n",
       "      <th>IIKI17_2</th>\n",
       "      <th>IRHH65_2</th>\n",
       "      <th>IIHH65_2</th>\n",
       "      <th>PRXRETRY</th>\n",
       "      <th>...</th>\n",
       "      <th>TOOLONG</th>\n",
       "      <th>TROUBUND</th>\n",
       "      <th>PDEN10</th>\n",
       "      <th>COUTYP2</th>\n",
       "      <th>MAIIN102</th>\n",
       "      <th>AIIND102</th>\n",
       "      <th>ANALWT_C</th>\n",
       "      <th>VESTR</th>\n",
       "      <th>VEREP</th>\n",
       "      <th>Criminal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25095143</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3884.805998</td>\n",
       "      <td>40026</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13005143</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1627.108106</td>\n",
       "      <td>40015</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67415143</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4344.957980</td>\n",
       "      <td>40024</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70925143</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>792.521931</td>\n",
       "      <td>40027</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75235143</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1518.118526</td>\n",
       "      <td>40001</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PERID  IFATHER  NRCH17_2  IRHHSIZ2  IIHHSIZ2  IRKI17_2  IIKI17_2  \\\n",
       "0  25095143        4         2         4         1         3         1   \n",
       "1  13005143        4         1         3         1         2         1   \n",
       "2  67415143        4         1         2         1         2         1   \n",
       "3  70925143        4         0         2         1         1         1   \n",
       "4  75235143        1         0         6         1         4         1   \n",
       "\n",
       "   IRHH65_2  IIHH65_2  PRXRETRY  ...  TOOLONG  TROUBUND  PDEN10  COUTYP2  \\\n",
       "0         1         1        99  ...        1         2       1        1   \n",
       "1         1         1        99  ...        2         2       2        3   \n",
       "2         1         1        99  ...        2         2       2        3   \n",
       "3         1         1        99  ...        2         2       1        1   \n",
       "4         1         1        99  ...        2         2       2        2   \n",
       "\n",
       "   MAIIN102  AIIND102     ANALWT_C  VESTR  VEREP  Criminal  \n",
       "0         2         2  3884.805998  40026      1         0  \n",
       "1         2         2  1627.108106  40015      2         1  \n",
       "2         2         2  4344.957980  40024      1         0  \n",
       "3         2         2   792.521931  40027      1         0  \n",
       "4         2         2  1518.118526  40001      2         0  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21d8aa37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45718 entries, 0 to 45717\n",
      "Data columns (total 72 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   PERID      45718 non-null  int64  \n",
      " 1   IFATHER    45718 non-null  int64  \n",
      " 2   NRCH17_2   45718 non-null  int64  \n",
      " 3   IRHHSIZ2   45718 non-null  int64  \n",
      " 4   IIHHSIZ2   45718 non-null  int64  \n",
      " 5   IRKI17_2   45718 non-null  int64  \n",
      " 6   IIKI17_2   45718 non-null  int64  \n",
      " 7   IRHH65_2   45718 non-null  int64  \n",
      " 8   IIHH65_2   45718 non-null  int64  \n",
      " 9   PRXRETRY   45718 non-null  int64  \n",
      " 10  PRXYDATA   45718 non-null  int64  \n",
      " 11  MEDICARE   45718 non-null  int64  \n",
      " 12  CAIDCHIP   45718 non-null  int64  \n",
      " 13  CHAMPUS    45718 non-null  int64  \n",
      " 14  PRVHLTIN   45718 non-null  int64  \n",
      " 15  GRPHLTIN   45718 non-null  int64  \n",
      " 16  HLTINNOS   45718 non-null  int64  \n",
      " 17  HLCNOTYR   45718 non-null  int64  \n",
      " 18  HLCNOTMO   45718 non-null  int64  \n",
      " 19  HLCLAST    45718 non-null  int64  \n",
      " 20  HLLOSRSN   45718 non-null  int64  \n",
      " 21  HLNVCOST   45718 non-null  int64  \n",
      " 22  HLNVOFFR   45718 non-null  int64  \n",
      " 23  HLNVREF    45718 non-null  int64  \n",
      " 24  HLNVNEED   45718 non-null  int64  \n",
      " 25  HLNVSOR    45718 non-null  int64  \n",
      " 26  IRMCDCHP   45718 non-null  int64  \n",
      " 27  IIMCDCHP   45718 non-null  int64  \n",
      " 28  IRMEDICR   45718 non-null  int64  \n",
      " 29  IIMEDICR   45718 non-null  int64  \n",
      " 30  IRCHMPUS   45718 non-null  int64  \n",
      " 31  IICHMPUS   45718 non-null  int64  \n",
      " 32  IRPRVHLT   45718 non-null  int64  \n",
      " 33  IIPRVHLT   45718 non-null  int64  \n",
      " 34  IROTHHLT   45718 non-null  int64  \n",
      " 35  IIOTHHLT   45718 non-null  int64  \n",
      " 36  HLCALLFG   45718 non-null  int64  \n",
      " 37  HLCALL99   45718 non-null  int64  \n",
      " 38  ANYHLTI2   45718 non-null  int64  \n",
      " 39  IRINSUR4   45718 non-null  int64  \n",
      " 40  IIINSUR4   45718 non-null  int64  \n",
      " 41  OTHINS     45718 non-null  int64  \n",
      " 42  CELLNOTCL  45718 non-null  int64  \n",
      " 43  CELLWRKNG  45718 non-null  int64  \n",
      " 44  IRFAMSOC   45718 non-null  int64  \n",
      " 45  IIFAMSOC   45718 non-null  int64  \n",
      " 46  IRFAMSSI   45718 non-null  int64  \n",
      " 47  IIFAMSSI   45718 non-null  int64  \n",
      " 48  IRFSTAMP   45718 non-null  int64  \n",
      " 49  IIFSTAMP   45718 non-null  int64  \n",
      " 50  IRFAMPMT   45718 non-null  int64  \n",
      " 51  IIFAMPMT   45718 non-null  int64  \n",
      " 52  IRFAMSVC   45718 non-null  int64  \n",
      " 53  IIFAMSVC   45718 non-null  int64  \n",
      " 54  IRWELMOS   45718 non-null  int64  \n",
      " 55  IIWELMOS   45718 non-null  int64  \n",
      " 56  IRPINC3    45718 non-null  int64  \n",
      " 57  IRFAMIN3   45718 non-null  int64  \n",
      " 58  IIPINC3    45718 non-null  int64  \n",
      " 59  IIFAMIN3   45718 non-null  int64  \n",
      " 60  GOVTPROG   45718 non-null  int64  \n",
      " 61  POVERTY3   45718 non-null  int64  \n",
      " 62  TOOLONG    45718 non-null  int64  \n",
      " 63  TROUBUND   45718 non-null  int64  \n",
      " 64  PDEN10     45718 non-null  int64  \n",
      " 65  COUTYP2    45718 non-null  int64  \n",
      " 66  MAIIN102   45718 non-null  int64  \n",
      " 67  AIIND102   45718 non-null  int64  \n",
      " 68  ANALWT_C   45718 non-null  float64\n",
      " 69  VESTR      45718 non-null  int64  \n",
      " 70  VEREP      45718 non-null  int64  \n",
      " 71  Criminal   45718 non-null  int64  \n",
      "dtypes: float64(1), int64(71)\n",
      "memory usage: 25.1 MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7df1743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PERID', 'IFATHER', 'NRCH17_2', 'IRHHSIZ2', 'IIHHSIZ2', 'IRKI17_2',\n",
       "       'IIKI17_2', 'IRHH65_2', 'IIHH65_2', 'PRXRETRY', 'PRXYDATA', 'MEDICARE',\n",
       "       'CAIDCHIP', 'CHAMPUS', 'PRVHLTIN', 'GRPHLTIN', 'HLTINNOS', 'HLCNOTYR',\n",
       "       'HLCNOTMO', 'HLCLAST', 'HLLOSRSN', 'HLNVCOST', 'HLNVOFFR', 'HLNVREF',\n",
       "       'HLNVNEED', 'HLNVSOR', 'IRMCDCHP', 'IIMCDCHP', 'IRMEDICR', 'IIMEDICR',\n",
       "       'IRCHMPUS', 'IICHMPUS', 'IRPRVHLT', 'IIPRVHLT', 'IROTHHLT', 'IIOTHHLT',\n",
       "       'HLCALLFG', 'HLCALL99', 'ANYHLTI2', 'IRINSUR4', 'IIINSUR4', 'OTHINS',\n",
       "       'CELLNOTCL', 'CELLWRKNG', 'IRFAMSOC', 'IIFAMSOC', 'IRFAMSSI',\n",
       "       'IIFAMSSI', 'IRFSTAMP', 'IIFSTAMP', 'IRFAMPMT', 'IIFAMPMT', 'IRFAMSVC',\n",
       "       'IIFAMSVC', 'IRWELMOS', 'IIWELMOS', 'IRPINC3', 'IRFAMIN3', 'IIPINC3',\n",
       "       'IIFAMIN3', 'GOVTPROG', 'POVERTY3', 'TOOLONG', 'TROUBUND', 'PDEN10',\n",
       "       'COUTYP2', 'MAIIN102', 'AIIND102', 'ANALWT_C', 'VESTR', 'VEREP',\n",
       "       'Criminal'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "123e5faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1839fb78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 42543), (1, 3175)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getLabelCount(df,target):\n",
    "    return sorted([( labelValue,len(df.loc[df[target] == labelValue]) ) for labelValue in df[target].unique()])\n",
    "TARGET = \"Criminal\"\n",
    "labelCount = getLabelCount(df_train,TARGET)\n",
    "labelCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10eadf4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Criminal'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train['Criminal'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3f2eee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToFloat(df):\n",
    "    df1 = df.copy()\n",
    "    \n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == 'int64' and column != 'Criminal':\n",
    "            df[column] = df[column].astype(float)\n",
    "    return df\n",
    "\n",
    "encoded_df = convertToFloat(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a402fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "b=df_train\n",
    "b.to_csv(\"preprocess.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ad46e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat = encoded_df.corr()\n",
    "top_corr_features = corrmat.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51095869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for  0.0005\n",
      "IFATHER     0.049935\n",
      "NRCH17_2    0.091212\n",
      "IRHHSIZ2    0.068281\n",
      "IIHHSIZ2    0.009238\n",
      "IRKI17_2    0.039168\n",
      "              ...   \n",
      "AIIND102    0.001484\n",
      "ANALWT_C    0.020863\n",
      "VESTR       0.002355\n",
      "VEREP       0.007738\n",
      "Criminal    1.000000\n",
      "Name: Criminal, Length: 71, dtype: float64\n",
      "------------------\n",
      "for  0.005\n",
      "IFATHER     0.049935\n",
      "NRCH17_2    0.091212\n",
      "IRHHSIZ2    0.068281\n",
      "IIHHSIZ2    0.009238\n",
      "IRKI17_2    0.039168\n",
      "              ...   \n",
      "PDEN10      0.033048\n",
      "COUTYP2     0.031587\n",
      "ANALWT_C    0.020863\n",
      "VEREP       0.007738\n",
      "Criminal    1.000000\n",
      "Name: Criminal, Length: 61, dtype: float64\n",
      "------------------\n",
      "for  0.09\n",
      "NRCH17_2    0.091212\n",
      "IRHH65_2    0.112589\n",
      "GRPHLTIN    0.194188\n",
      "HLTINNOS    0.106967\n",
      "HLCLAST     0.091338\n",
      "IRMEDICR    0.144131\n",
      "IRPRVHLT    0.204797\n",
      "IIPRVHLT    0.103360\n",
      "IROTHHLT    0.104196\n",
      "IIOTHHLT    0.095032\n",
      "IRFAMSOC    0.110676\n",
      "IRPINC3     0.128830\n",
      "IRFAMIN3    0.194889\n",
      "POVERTY3    0.148304\n",
      "Criminal    1.000000\n",
      "Name: Criminal, dtype: float64\n",
      "------------------\n",
      "for  0.5\n",
      "Criminal    1.0\n",
      "Name: Criminal, dtype: float64\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "correlationdistance=[0.0005,0.005,0.09,0.5]\n",
    "#Correlation with output variable\n",
    "cor_target = abs(encoded_df[top_corr_features].corr()[\"Criminal\"])\n",
    "for correVal in correlationdistance:\n",
    "#Selecting highly correlated features\n",
    "    relevant_features = cor_target[cor_target>correVal]\n",
    "    print('for ',correVal)\n",
    "    print(relevant_features)\n",
    "    print('------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc669495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'NRCH17_2': Number of Children Aged 0-17 in Household\n",
    "# 'IRHH65_2': Number of Household Members Aged 65 or Older (Interview)\n",
    "# 'GRPHLTIN': Group Health Plan Coverage\n",
    "# 'HLTINNOS': Health Insurance Type - Other\n",
    "# 'HLCLAST': Time Since Last Health Insurance Type Change\n",
    "# 'IRMEDICR': Medicare (Imputed)\n",
    "# 'IRPRVHLT': Private Health Insurance (Imputed)\n",
    "# 'IROTHHLT': Other Health Insurance (Imputed)\n",
    "# 'IRFAMSOC': Family's Social Class (Interview)\n",
    "# 'IRPINC3': Family's Poverty Income Ratio (Interview)\n",
    "# 'POVERTY3': Poverty Level\n",
    "# 'Criminal': Binary variable indicating criminal activity (assuming based on the name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd3faf9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NRCH17_2',\n",
       " 'IRHH65_2',\n",
       " 'GRPHLTIN',\n",
       " 'HLTINNOS',\n",
       " 'HLCLAST',\n",
       " 'IRMEDICR',\n",
       " 'IRPRVHLT',\n",
       " 'IROTHHLT',\n",
       " 'IRFAMSOC',\n",
       " 'IRPINC3',\n",
       " 'POVERTY3',\n",
       " 'Criminal']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_col = ['NRCH17_2','IRHH65_2','GRPHLTIN','HLTINNOS','HLCLAST','IRMEDICR',\n",
    "               'IRPRVHLT','IROTHHLT','IRFAMSOC','IRPINC3','POVERTY3','Criminal']\n",
    "selected_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49ff0487",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df=encoded_df[selected_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b13f068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NRCH17_2</th>\n",
       "      <th>IRHH65_2</th>\n",
       "      <th>GRPHLTIN</th>\n",
       "      <th>HLTINNOS</th>\n",
       "      <th>HLCLAST</th>\n",
       "      <th>IRMEDICR</th>\n",
       "      <th>IRPRVHLT</th>\n",
       "      <th>IROTHHLT</th>\n",
       "      <th>IRFAMSOC</th>\n",
       "      <th>IRPINC3</th>\n",
       "      <th>POVERTY3</th>\n",
       "      <th>Criminal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45713</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45714</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45715</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45716</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45717</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45718 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       NRCH17_2  IRHH65_2  GRPHLTIN  HLTINNOS  HLCLAST  IRMEDICR  IRPRVHLT  \\\n",
       "0           2.0       1.0      99.0      99.0     99.0       2.0       2.0   \n",
       "1           1.0       1.0       1.0      99.0     99.0       2.0       1.0   \n",
       "2           1.0       1.0      99.0      99.0     99.0       2.0       2.0   \n",
       "3           0.0       1.0       1.0      99.0     99.0       2.0       1.0   \n",
       "4           0.0       1.0      99.0      99.0     99.0       2.0       2.0   \n",
       "...         ...       ...       ...       ...      ...       ...       ...   \n",
       "45713       1.0       1.0      99.0       2.0      5.0       2.0       2.0   \n",
       "45714       0.0       2.0      99.0      99.0     99.0       1.0       2.0   \n",
       "45715       0.0       2.0      99.0       2.0      2.0       2.0       2.0   \n",
       "45716       0.0       1.0      99.0       1.0     99.0       2.0       2.0   \n",
       "45717       0.0       1.0       1.0      99.0     99.0       2.0       1.0   \n",
       "\n",
       "       IROTHHLT  IRFAMSOC  IRPINC3  POVERTY3  Criminal  \n",
       "0          99.0       2.0      1.0       2.0         0  \n",
       "1          99.0       2.0      1.0       1.0         1  \n",
       "2          99.0       1.0      2.0       1.0         0  \n",
       "3          99.0       2.0      7.0       3.0         0  \n",
       "4          99.0       2.0      1.0       1.0         0  \n",
       "...         ...       ...      ...       ...       ...  \n",
       "45713       2.0       2.0      4.0       2.0         0  \n",
       "45714      99.0       1.0      2.0       3.0         0  \n",
       "45715       2.0       1.0      2.0       2.0         0  \n",
       "45716       1.0       2.0      4.0       3.0         0  \n",
       "45717      99.0       2.0      6.0       3.0         0  \n",
       "\n",
       "[45718 rows x 12 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3484644",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp\\ipykernel_8808\\580172998.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  encoded_df[col] = scaled[col]\n"
     ]
    }
   ],
   "source": [
    "to_scale = [col for col in encoded_df.columns if encoded_df[col].max()>1]\n",
    "scaler = RobustScaler()\n",
    "scaled =scaler.fit_transform(encoded_df[to_scale])\n",
    "scaled = pd.DataFrame(scaled, columns=to_scale)\n",
    "\n",
    "# replace original columns with scaled columns\n",
    "for col in scaled:\n",
    "    encoded_df[col] = scaled[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0da9f78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NRCH17_2',\n",
       " 'IRHH65_2',\n",
       " 'GRPHLTIN',\n",
       " 'HLTINNOS',\n",
       " 'HLCLAST',\n",
       " 'IRMEDICR',\n",
       " 'IRPRVHLT',\n",
       " 'IROTHHLT',\n",
       " 'IRFAMSOC',\n",
       " 'IRPINC3',\n",
       " 'POVERTY3']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a77b2be4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NRCH17_2</th>\n",
       "      <th>IRHH65_2</th>\n",
       "      <th>GRPHLTIN</th>\n",
       "      <th>HLTINNOS</th>\n",
       "      <th>HLCLAST</th>\n",
       "      <th>IRMEDICR</th>\n",
       "      <th>IRPRVHLT</th>\n",
       "      <th>IROTHHLT</th>\n",
       "      <th>IRFAMSOC</th>\n",
       "      <th>IRPINC3</th>\n",
       "      <th>POVERTY3</th>\n",
       "      <th>Criminal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45713</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-97.0</td>\n",
       "      <td>-94.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-97.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45714</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45715</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-97.0</td>\n",
       "      <td>-97.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-97.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45716</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-98.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-98.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45717</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45718 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       NRCH17_2  IRHH65_2  GRPHLTIN  HLTINNOS  HLCLAST  IRMEDICR  IRPRVHLT  \\\n",
       "0           2.0       0.0       1.0       0.0      0.0       0.0       1.0   \n",
       "1           1.0       0.0       0.0       0.0      0.0       0.0       0.0   \n",
       "2           1.0       0.0       1.0       0.0      0.0       0.0       1.0   \n",
       "3           0.0       0.0       0.0       0.0      0.0       0.0       0.0   \n",
       "4           0.0       0.0       1.0       0.0      0.0       0.0       1.0   \n",
       "...         ...       ...       ...       ...      ...       ...       ...   \n",
       "45713       1.0       0.0       1.0     -97.0    -94.0       0.0       1.0   \n",
       "45714       0.0       1.0       1.0       0.0      0.0      -1.0       1.0   \n",
       "45715       0.0       1.0       1.0     -97.0    -97.0       0.0       1.0   \n",
       "45716       0.0       0.0       1.0     -98.0      0.0       0.0       1.0   \n",
       "45717       0.0       0.0       0.0       0.0      0.0       0.0       0.0   \n",
       "\n",
       "       IROTHHLT  IRFAMSOC   IRPINC3  POVERTY3  Criminal  \n",
       "0           0.0       0.0 -0.333333      -1.0         0  \n",
       "1           0.0       0.0 -0.333333      -2.0         1  \n",
       "2           0.0      -1.0  0.000000      -2.0         0  \n",
       "3           0.0       0.0  1.666667       0.0         0  \n",
       "4           0.0       0.0 -0.333333      -2.0         0  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "45713     -97.0       0.0  0.666667      -1.0         0  \n",
       "45714       0.0      -1.0  0.000000       0.0         0  \n",
       "45715     -97.0      -1.0  0.000000      -1.0         0  \n",
       "45716     -98.0       0.0  0.666667       0.0         0  \n",
       "45717       0.0       0.0  1.333333       0.0         0  \n",
       "\n",
       "[45718 rows x 12 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f1b10fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45718, 11)\n",
      "(45718,)\n"
     ]
    }
   ],
   "source": [
    "X=encoded_df.drop(['Criminal'], axis=1)\n",
    "Y=encoded_df['Criminal']\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e1f9bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split the data into training and testing sets\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, Y, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74135dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34288, 11)\n",
      "(11430, 11)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bae43d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE \n",
    "smote = SMOTE()\n",
    "X_train_new, y_train_new = smote.fit_resample(X_train, y_train.values.ravel())\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "# to demonstrate the effect of SMOTE over imbalanced datasets\n",
    "fig, (ax1, ax2) = plt.subplots(ncols = 2, figsize =(15, 5))\n",
    "ax1.set_title('Before SMOTE')\n",
    "pd.Series(y_train).value_counts().plot.pie(autopct='%.1f%%',ax=ax1)\n",
    "ax1.yaxis.set_major_formatter(mtick.PercentFormatter())\n",
    "ax2.set_title('After SMOTE')  \n",
    "pd.Series(y_train_new).value_counts().plot.pie(autopct='%.1f%%',ax=ax2)\n",
    "ax2.yaxis.set_major_formatter(mtick.PercentFormatter())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a528c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lr =  LogisticRegression()\n",
    "lr.fit(X_train_new, y_train_new)\n",
    "y_pred=lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "84db4042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Logistic Regression: 0.8712160979877516\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy Logistic Regression:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c48296f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[ 692  110]\n",
      " [1362 9266]]\n",
      "Outcome values : \n",
      " 692 110 1362 9266\n",
      "Classification report Logistic Regression : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.34      0.86      0.48       802\n",
      "           0       0.99      0.87      0.93     10628\n",
      "\n",
      "    accuracy                           0.87     11430\n",
      "   macro avg       0.66      0.87      0.71     11430\n",
      "weighted avg       0.94      0.87      0.90     11430\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# actual values\n",
    "actual = y_test\n",
    "# predicted values\n",
    "predicted =y_pred\n",
    "\n",
    "# confusion matrix\n",
    "matrixresult = confusion_matrix(actual,predicted, labels=[1,0])\n",
    "print('Confusion matrix : \\n',matrixresult)\n",
    "\n",
    "# outcome values order in sklearn\n",
    "tp, fn, fp, tn = confusion_matrix(actual,predicted,labels=[1,0]).reshape(-1)\n",
    "print('Outcome values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "matrix = classification_report(actual,predicted,labels=[1,0])\n",
    "print('Classification report Logistic Regression : \\n',matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d1d01e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression: 0.8712160979877516\n",
      "Model saved as models/Logistic_Regression_Classify_model.joblib\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"LogisticRegression:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Save the trained model to a file using joblib\n",
    "model_filename1 = \"models/Logistic_Regression_Classify_model.joblib\"\n",
    "joblib.dump(lr, model_filename1)\n",
    "print(f\"Model saved as {model_filename1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bb7022",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "59a6da4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "classifier= KNeighborsClassifier(n_neighbors=3)  \n",
    "classifier.fit(X_train_new, y_train_new)  \n",
    "y_pred4=classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5fb01428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy KNN: 0.9352580927384077\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Accuracy KNN:\",metrics.accuracy_score(y_test, y_pred4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5fdaecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[  361   441]\n",
      " [  299 10329]]\n",
      "Outcome values : \n",
      " 361 441 299 10329\n",
      "Classification KNeighborsClassifier : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.45      0.49       802\n",
      "           0       0.96      0.97      0.97     10628\n",
      "\n",
      "    accuracy                           0.94     11430\n",
      "   macro avg       0.75      0.71      0.73     11430\n",
      "weighted avg       0.93      0.94      0.93     11430\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# actual values\n",
    "actual = y_test\n",
    "# predicted values\n",
    "predicted =y_pred4\n",
    "\n",
    "# confusion matrix\n",
    "matrixresult = confusion_matrix(actual,predicted, labels=[1,0])\n",
    "print('Confusion matrix : \\n',matrixresult)\n",
    "\n",
    "# outcome values order in sklearn\n",
    "tp, fn, fp, tn = confusion_matrix(actual,predicted,labels=[1,0]).reshape(-1)\n",
    "print('Outcome values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "matrix = classification_report(actual,predicted,labels=[1,0])\n",
    "print('Classification KNeighborsClassifier : \\n',matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "87472507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier : 0.9352580927384077\n",
      "Model saved as models/KNeighbors_Classifier_Classify_model.joblib\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"KNeighborsClassifier :\",metrics.accuracy_score(y_test, y_pred4))\n",
    "\n",
    "# Save the trained model to a file using joblib\n",
    "model_filename1 = \"models/KNeighbors_Classifier_Classify_model.joblib\"\n",
    "joblib.dump(classifier, model_filename1)\n",
    "print(f\"Model saved as {model_filename1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a5c5a8c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred4[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0eae280",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ea16377d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an instance of the DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Fit the model to your training data\n",
    "clf.fit(X_train_new, y_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e761c557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy DecisionTreeClassifier: 0.8875765529308837\n"
     ]
    }
   ],
   "source": [
    "y_pred1 = clf.predict(X_test)\n",
    "print(\"Accuracy DecisionTreeClassifier:\",metrics.accuracy_score(y_test, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4887b6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[ 657  145]\n",
      " [1140 9488]]\n",
      "Outcome values : \n",
      " 657 145 1140 9488\n",
      "Classification DecisionTreeClassifier : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.37      0.82      0.51       802\n",
      "           0       0.98      0.89      0.94     10628\n",
      "\n",
      "    accuracy                           0.89     11430\n",
      "   macro avg       0.68      0.86      0.72     11430\n",
      "weighted avg       0.94      0.89      0.91     11430\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# actual values\n",
    "actual = y_test\n",
    "# predicted values\n",
    "predicted =y_pred1\n",
    "\n",
    "# confusion matrix\n",
    "matrixresult = confusion_matrix(actual,predicted, labels=[1,0])\n",
    "print('Confusion matrix : \\n',matrixresult)\n",
    "\n",
    "# outcome values order in sklearn\n",
    "tp, fn, fp, tn = confusion_matrix(actual,predicted,labels=[1,0]).reshape(-1)\n",
    "print('Outcome values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "matrix = classification_report(actual,predicted,labels=[1,0])\n",
    "print('Classification DecisionTreeClassifier : \\n',matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "842e5a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier  : 0.8875765529308837\n",
      "Model saved as models/DecisionTree_Classifier_Classify_model.joblib\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"DecisionTreeClassifier  :\",metrics.accuracy_score(y_test, y_pred1))\n",
    "\n",
    "# Save the trained model to a file using joblib\n",
    "model_filename1 = \"models/DecisionTree_Classifier_Classify_model.joblib\"\n",
    "joblib.dump(classifier, model_filename1)\n",
    "print(f\"Model saved as {model_filename1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010d6ae9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6c2f1387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an instance of the DecisionTreeClassifier\n",
    "random = RandomForestClassifier()\n",
    "\n",
    "# Fit the model to your training data\n",
    "random.fit(X_train_new, y_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7b1b2274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "y_pred5 = random.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "770992d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[ 660  142]\n",
      " [1142 9486]]\n",
      "Outcome values : \n",
      " 660 142 1142 9486\n",
      "Classification SVC : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.37      0.82      0.51       802\n",
      "           0       0.99      0.89      0.94     10628\n",
      "\n",
      "    accuracy                           0.89     11430\n",
      "   macro avg       0.68      0.86      0.72     11430\n",
      "weighted avg       0.94      0.89      0.91     11430\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# actual values\n",
    "actual = y_test\n",
    "# predicted values\n",
    "predicted =y_pred5\n",
    "\n",
    "# confusion matrix\n",
    "matrixresult = confusion_matrix(actual,predicted, labels=[1,0])\n",
    "print('Confusion matrix : \\n',matrixresult)\n",
    "\n",
    "# outcome values order in sklearn\n",
    "tp, fn, fp, tn = confusion_matrix(actual,predicted,labels=[1,0]).reshape(-1)\n",
    "print('Outcome values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "matrix = classification_report(actual,predicted,labels=[1,0])\n",
    "print('Classification SVC : \\n',matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "38c04d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as models/RandomForestClassifier_Classify_model.joblib\n"
     ]
    }
   ],
   "source": [
    "model_filename15 = \"models/RandomForestClassifier_Classify_model.joblib\"\n",
    "joblib.dump(random, model_filename15)\n",
    "print(f\"Model saved as {model_filename15}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8339ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6333c80b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c1c384",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bec44af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier \n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f7aa48d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = AdaBoostClassifier(DecisionTreeClassifier(max_depth=9),n_estimators=150)\n",
    "ada.fit(X_train_new, y_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "32bbba94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada.score(X_test,y_test)\n",
    "predictions_ada = ada.predict(X_test)\n",
    "predictions_ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "77b6c2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[ 654  148]\n",
      " [1137 9491]]\n",
      "Outcome values : \n",
      " 654 148 1137 9491\n",
      "Classification AdaBoostClassifier : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.37      0.82      0.50       802\n",
      "           0       0.98      0.89      0.94     10628\n",
      "\n",
      "    accuracy                           0.89     11430\n",
      "   macro avg       0.67      0.85      0.72     11430\n",
      "weighted avg       0.94      0.89      0.91     11430\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# actual values\n",
    "actual = y_test\n",
    "# predicted values\n",
    "predicted =predictions_ada\n",
    "\n",
    "# confusion matrix\n",
    "matrixresult = confusion_matrix(actual,predicted, labels=[1,0])\n",
    "print('Confusion matrix : \\n',matrixresult)\n",
    "\n",
    "# outcome values order in sklearn\n",
    "tp, fn, fp, tn = confusion_matrix(actual,predicted,labels=[1,0]).reshape(-1)\n",
    "print('Outcome values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "matrix = classification_report(actual,predicted,labels=[1,0])\n",
    "print('Classification AdaBoostClassifier : \\n',matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "61696e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as models/AdaBoostClassifier_model.joblib\n"
     ]
    }
   ],
   "source": [
    "model_filename_ada = \"models/AdaBoostClassifier_model.joblib\"\n",
    "joblib.dump(random, model_filename_ada)\n",
    "print(f\"Model saved as {model_filename_ada}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01add375",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69338f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b5cf33ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2bc3dd82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ExtraTreesClassifier(random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExtraTreesClassifier</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesClassifier(random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "ExtraTreesClassifier(random_state=0)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ETC = ExtraTreesClassifier(n_estimators=100, random_state=0)\n",
    "ETC.fit(X_train_new, y_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4f0c7a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score achieved using ExtraTrees Classifier is: 88.79 %\n"
     ]
    }
   ],
   "source": [
    "ETC_predictions = ETC.predict(X_test)\n",
    "\n",
    "score_ETC=round(accuracy_score(ETC_predictions,y_test)*100,2)\n",
    "print(\"The accuracy score achieved using ExtraTrees Classifier is: \"+str(score_ETC)+\" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "27c55335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[ 656  146]\n",
      " [1135 9493]]\n",
      "Outcome values : \n",
      " 656 146 1135 9493\n",
      "Classification ExtraTreesClassifier : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.37      0.82      0.51       802\n",
      "           0       0.98      0.89      0.94     10628\n",
      "\n",
      "    accuracy                           0.89     11430\n",
      "   macro avg       0.68      0.86      0.72     11430\n",
      "weighted avg       0.94      0.89      0.91     11430\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# actual values\n",
    "actual = y_test\n",
    "# predicted values\n",
    "predicted =ETC_predictions\n",
    "\n",
    "# confusion matrix\n",
    "matrixresult = confusion_matrix(actual,predicted, labels=[1,0])\n",
    "print('Confusion matrix : \\n',matrixresult)\n",
    "\n",
    "# outcome values order in sklearn\n",
    "tp, fn, fp, tn = confusion_matrix(actual,predicted,labels=[1,0]).reshape(-1)\n",
    "print('Outcome values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "matrix = classification_report(actual,predicted,labels=[1,0])\n",
    "print('Classification ExtraTreesClassifier : \\n',matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e63d0637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as models/ExtraTreesClassifier.joblib\n"
     ]
    }
   ],
   "source": [
    "model_filename_ETree = \"models/ExtraTreesClassifier.joblib\"\n",
    "joblib.dump(random, model_filename_ETree)\n",
    "print(f\"Model saved as {model_filename_ETree}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c46725d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8beb326b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a86190",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a35e5521",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "model=tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(20,input_shape=X_train_new.shape[1:],activation='relu'),\n",
    "    tf.keras.layers.Dense(10,activation='relu'),\n",
    "    tf.keras.layers.Dense(22,activation='sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4eedeb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e3dd56c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.8481 - accuracy: 0.4684\n",
      "Epoch 2/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.2643 - accuracy: 0.5000\n",
      "Epoch 3/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3324 - accuracy: 0.5000\n",
      "Epoch 4/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8362 - accuracy: 0.5000\n",
      "Epoch 5/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7113 - accuracy: 0.5000\n",
      "Epoch 6/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6716 - accuracy: 0.5000\n",
      "Epoch 7/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6541 - accuracy: 0.5000\n",
      "Epoch 8/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6189 - accuracy: 0.5000\n",
      "Epoch 9/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5757 - accuracy: 0.5000\n",
      "Epoch 10/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5350 - accuracy: 0.5000\n",
      "Epoch 11/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5203 - accuracy: 0.5000\n",
      "Epoch 12/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5151 - accuracy: 0.5000\n",
      "Epoch 13/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5123 - accuracy: 0.5000\n",
      "Epoch 14/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5104 - accuracy: 0.5000\n",
      "Epoch 15/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5092 - accuracy: 0.5000\n",
      "Epoch 16/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5079 - accuracy: 0.5000\n",
      "Epoch 17/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5067 - accuracy: 0.5000\n",
      "Epoch 18/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5060 - accuracy: 0.5000\n",
      "Epoch 19/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5052 - accuracy: 0.5000\n",
      "Epoch 20/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5047 - accuracy: 0.5000\n",
      "Epoch 21/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5042 - accuracy: 0.5000\n",
      "Epoch 22/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5038 - accuracy: 0.5000\n",
      "Epoch 23/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5033 - accuracy: 0.5000\n",
      "Epoch 24/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5028 - accuracy: 0.5000\n",
      "Epoch 25/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5025 - accuracy: 0.5000\n",
      "Epoch 26/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5021 - accuracy: 0.5000\n",
      "Epoch 27/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5019 - accuracy: 0.5000\n",
      "Epoch 28/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5019 - accuracy: 0.5000\n",
      "Epoch 29/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5013 - accuracy: 0.5000\n",
      "Epoch 30/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5010 - accuracy: 0.5000\n",
      "Epoch 31/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5006 - accuracy: 0.5000\n",
      "Epoch 32/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5004 - accuracy: 0.5000\n",
      "Epoch 33/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5002 - accuracy: 0.5000\n",
      "Epoch 34/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4999 - accuracy: 0.5000\n",
      "Epoch 35/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4999 - accuracy: 0.5000\n",
      "Epoch 36/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4995 - accuracy: 0.5000\n",
      "Epoch 37/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4993 - accuracy: 0.5000\n",
      "Epoch 38/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4991 - accuracy: 0.5000\n",
      "Epoch 39/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4989 - accuracy: 0.5000\n",
      "Epoch 40/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4985 - accuracy: 0.5000\n",
      "Epoch 41/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4982 - accuracy: 0.5000\n",
      "Epoch 42/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4982 - accuracy: 0.5000\n",
      "Epoch 43/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4981 - accuracy: 0.5000\n",
      "Epoch 44/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4978 - accuracy: 0.5000\n",
      "Epoch 45/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4972 - accuracy: 0.5000\n",
      "Epoch 46/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4968 - accuracy: 0.5000\n",
      "Epoch 47/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4964 - accuracy: 0.5000\n",
      "Epoch 48/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4962 - accuracy: 0.5000\n",
      "Epoch 49/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4956 - accuracy: 0.5000\n",
      "Epoch 50/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4952 - accuracy: 0.5000\n",
      "Epoch 51/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4948 - accuracy: 0.5000\n",
      "Epoch 52/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4947 - accuracy: 0.5000\n",
      "Epoch 53/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4942 - accuracy: 0.5000\n",
      "Epoch 54/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4941 - accuracy: 0.5000\n",
      "Epoch 55/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4934 - accuracy: 0.5000\n",
      "Epoch 56/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4931 - accuracy: 0.5000\n",
      "Epoch 57/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4926 - accuracy: 0.5000\n",
      "Epoch 58/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4925 - accuracy: 0.5000\n",
      "Epoch 59/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4921 - accuracy: 0.5000\n",
      "Epoch 60/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4919 - accuracy: 0.5000\n",
      "Epoch 61/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4917 - accuracy: 0.5000\n",
      "Epoch 62/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4912 - accuracy: 0.5000\n",
      "Epoch 63/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4910 - accuracy: 0.5000\n",
      "Epoch 64/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4907 - accuracy: 0.5000\n",
      "Epoch 65/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4905 - accuracy: 0.5000\n",
      "Epoch 66/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4903 - accuracy: 0.5000\n",
      "Epoch 67/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4898 - accuracy: 0.5000\n",
      "Epoch 68/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4898 - accuracy: 0.5000\n",
      "Epoch 69/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4896 - accuracy: 0.5000\n",
      "Epoch 70/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4893 - accuracy: 0.5000\n",
      "Epoch 71/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4891 - accuracy: 0.5000\n",
      "Epoch 72/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4895 - accuracy: 0.5000\n",
      "Epoch 73/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4889 - accuracy: 0.5000\n",
      "Epoch 74/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4888 - accuracy: 0.5000\n",
      "Epoch 75/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4887 - accuracy: 0.5000\n",
      "Epoch 76/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4885 - accuracy: 0.5000\n",
      "Epoch 77/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4883 - accuracy: 0.5000\n",
      "Epoch 78/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4883 - accuracy: 0.5000\n",
      "Epoch 79/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4886 - accuracy: 0.5000\n",
      "Epoch 80/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4882 - accuracy: 0.5000\n",
      "Epoch 81/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4880 - accuracy: 0.5000\n",
      "Epoch 82/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4882 - accuracy: 0.5000\n",
      "Epoch 83/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4881 - accuracy: 0.5000\n",
      "Epoch 84/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4879 - accuracy: 0.5000\n",
      "Epoch 85/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4879 - accuracy: 0.5000\n",
      "Epoch 86/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4877 - accuracy: 0.5000\n",
      "Epoch 87/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4877 - accuracy: 0.5000\n",
      "Epoch 88/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4877 - accuracy: 0.5000\n",
      "Epoch 89/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4877 - accuracy: 0.5000\n",
      "Epoch 90/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4876 - accuracy: 0.5000\n",
      "Epoch 91/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4873 - accuracy: 0.5000\n",
      "Epoch 92/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4875 - accuracy: 0.5000\n",
      "Epoch 93/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4873 - accuracy: 0.5000\n",
      "Epoch 94/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4872 - accuracy: 0.5000\n",
      "Epoch 95/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4871 - accuracy: 0.5000\n",
      "Epoch 96/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4870 - accuracy: 0.5000\n",
      "Epoch 97/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4870 - accuracy: 0.5000\n",
      "Epoch 98/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4869 - accuracy: 0.5000\n",
      "Epoch 99/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4872 - accuracy: 0.5000\n",
      "Epoch 100/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4869 - accuracy: 0.5000\n",
      "Epoch 101/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4867 - accuracy: 0.5000\n",
      "Epoch 102/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4867 - accuracy: 0.5000\n",
      "Epoch 103/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4870 - accuracy: 0.5000\n",
      "Epoch 104/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4867 - accuracy: 0.5000\n",
      "Epoch 105/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4865 - accuracy: 0.5000\n",
      "Epoch 106/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4864 - accuracy: 0.5000\n",
      "Epoch 107/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4864 - accuracy: 0.5000\n",
      "Epoch 108/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4865 - accuracy: 0.5000\n",
      "Epoch 109/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4867 - accuracy: 0.5000\n",
      "Epoch 110/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4864 - accuracy: 0.5000\n",
      "Epoch 111/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4862 - accuracy: 0.5000\n",
      "Epoch 112/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4862 - accuracy: 0.5000\n",
      "Epoch 113/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4861 - accuracy: 0.5000\n",
      "Epoch 114/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4861 - accuracy: 0.5000\n",
      "Epoch 115/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4860 - accuracy: 0.5000\n",
      "Epoch 116/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4859 - accuracy: 0.5000\n",
      "Epoch 117/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4860 - accuracy: 0.5000\n",
      "Epoch 118/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4866 - accuracy: 0.5000\n",
      "Epoch 119/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4863 - accuracy: 0.5000\n",
      "Epoch 120/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4863 - accuracy: 0.5000\n",
      "Epoch 121/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4863 - accuracy: 0.5000\n",
      "Epoch 122/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4863 - accuracy: 0.5000\n",
      "Epoch 123/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4861 - accuracy: 0.5000\n",
      "Epoch 124/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4858 - accuracy: 0.5000\n",
      "Epoch 125/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4856 - accuracy: 0.5000\n",
      "Epoch 126/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4856 - accuracy: 0.5000\n",
      "Epoch 127/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4857 - accuracy: 0.5000\n",
      "Epoch 128/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4857 - accuracy: 0.5000\n",
      "Epoch 129/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4856 - accuracy: 0.5000\n",
      "Epoch 130/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4855 - accuracy: 0.5000\n",
      "Epoch 131/200\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4852 - accuracy: 0.5000\n",
      "Epoch 132/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4852 - accuracy: 0.5000\n",
      "Epoch 133/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4851 - accuracy: 0.5000\n",
      "Epoch 134/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4853 - accuracy: 0.5000\n",
      "Epoch 135/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4853 - accuracy: 0.5000\n",
      "Epoch 136/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4854 - accuracy: 0.5000\n",
      "Epoch 137/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4853 - accuracy: 0.5000\n",
      "Epoch 138/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4852 - accuracy: 0.5000\n",
      "Epoch 139/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4850 - accuracy: 0.5000\n",
      "Epoch 140/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4851 - accuracy: 0.5000\n",
      "Epoch 141/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4852 - accuracy: 0.5000\n",
      "Epoch 142/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4853 - accuracy: 0.5000\n",
      "Epoch 143/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4853 - accuracy: 0.5000\n",
      "Epoch 144/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4851 - accuracy: 0.5000\n",
      "Epoch 145/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4851 - accuracy: 0.5000\n",
      "Epoch 146/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4851 - accuracy: 0.5000\n",
      "Epoch 147/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4853 - accuracy: 0.5000\n",
      "Epoch 148/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4852 - accuracy: 0.5000\n",
      "Epoch 149/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4850 - accuracy: 0.5000\n",
      "Epoch 150/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4848 - accuracy: 0.5000\n",
      "Epoch 151/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4848 - accuracy: 0.5000\n",
      "Epoch 152/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4852 - accuracy: 0.5000\n",
      "Epoch 153/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4852 - accuracy: 0.5000\n",
      "Epoch 154/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4850 - accuracy: 0.5000\n",
      "Epoch 155/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4850 - accuracy: 0.5000\n",
      "Epoch 156/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4848 - accuracy: 0.5000\n",
      "Epoch 157/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4850 - accuracy: 0.5000\n",
      "Epoch 158/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4849 - accuracy: 0.5000\n",
      "Epoch 159/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4849 - accuracy: 0.5000\n",
      "Epoch 160/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4849 - accuracy: 0.5000\n",
      "Epoch 161/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4846 - accuracy: 0.5000\n",
      "Epoch 162/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4845 - accuracy: 0.5000\n",
      "Epoch 163/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4846 - accuracy: 0.5000\n",
      "Epoch 164/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4849 - accuracy: 0.5000\n",
      "Epoch 165/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4849 - accuracy: 0.5000\n",
      "Epoch 166/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4848 - accuracy: 0.5000\n",
      "Epoch 167/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4852 - accuracy: 0.5000\n",
      "Epoch 168/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4848 - accuracy: 0.5000\n",
      "Epoch 169/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4846 - accuracy: 0.5000\n",
      "Epoch 170/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4846 - accuracy: 0.5000\n",
      "Epoch 171/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4845 - accuracy: 0.5000\n",
      "Epoch 172/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4846 - accuracy: 0.5000\n",
      "Epoch 173/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4843 - accuracy: 0.5000\n",
      "Epoch 174/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4843 - accuracy: 0.5000\n",
      "Epoch 175/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4843 - accuracy: 0.5000\n",
      "Epoch 176/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4850 - accuracy: 0.5000\n",
      "Epoch 177/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4844 - accuracy: 0.5000\n",
      "Epoch 178/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4844 - accuracy: 0.5000\n",
      "Epoch 179/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4843 - accuracy: 0.5000\n",
      "Epoch 180/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4842 - accuracy: 0.5000\n",
      "Epoch 181/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4844 - accuracy: 0.5000\n",
      "Epoch 182/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4843 - accuracy: 0.5000\n",
      "Epoch 183/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4843 - accuracy: 0.5000\n",
      "Epoch 184/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4843 - accuracy: 0.5000\n",
      "Epoch 185/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4842 - accuracy: 0.5000\n",
      "Epoch 186/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4843 - accuracy: 0.5000\n",
      "Epoch 187/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4842 - accuracy: 0.5000\n",
      "Epoch 188/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4842 - accuracy: 0.5000\n",
      "Epoch 189/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4845 - accuracy: 0.5003\n",
      "Epoch 190/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4845 - accuracy: 0.5003\n",
      "Epoch 191/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4845 - accuracy: 0.5003\n",
      "Epoch 192/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4847 - accuracy: 0.5005\n",
      "Epoch 193/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4846 - accuracy: 0.5004\n",
      "Epoch 194/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4849 - accuracy: 0.5010\n",
      "Epoch 195/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4844 - accuracy: 0.5006\n",
      "Epoch 196/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4841 - accuracy: 0.5013\n",
      "Epoch 197/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4840 - accuracy: 0.5013\n",
      "Epoch 198/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4842 - accuracy: 0.5020\n",
      "Epoch 199/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4846 - accuracy: 0.5026\n",
      "Epoch 200/200\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4844 - accuracy: 0.5027\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x134d4380dc0>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_new, y_train_new,epochs=200, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e1e04777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358/358 [==============================] - 0s 603us/step - loss: 0.2442 - accuracy: 0.9220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.24421384930610657, 0.9220472574234009]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7e767c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: NN_Criminal.hp5\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('NN_Criminal.hp5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4764a19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
